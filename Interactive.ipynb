{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import argparse\r\n",
        "import os\r\n",
        "import glob\r\n",
        "import shutil\r\n",
        "import joblib\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from pandas import read_csv\r\n",
        "\r\n",
        "from sklearn import __version__ as sklearnver\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder, LabelEncoder\r\n",
        "from sklearn.compose import make_column_transformer\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from azureml.core.model import Model\r\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\r\n",
        "\r\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset\r\n",
        "from packaging.version import Version"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\r\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "distributeddeeplearningqmx\ndeep-learning-challenge\nwestus2\n3df1840f-dd4b-4f54-a831-e20536439b3a\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# List the files in the mounted path\n",
        "print(os.listdir(\"/home/azureuser/cloudfiles/data/datastore/generalpurposeaccount\"))\n",
        "\n",
        "# Get the path of your file and load the data using your preferred libraries\n",
        "# import pandas as pd\n",
        "# df = pd.read_csv(\"/home/azureuser/cloudfiles/data/datastore/generalpurposeaccount/{path_to_file}/{your_file}\")\n",
        "# print(df.head(5))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['titanic_test.parquet', 'UI', 'azureml', 'dataset-demo', 'nlp_automl', 'pdf_titanic_3.csv', 'pipeline_inputdataset', 'temp_delta', 'titanic_dataset', 'titanic_feature', 'tweet.py']\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_titanic_raw = pd.read_parquet('/home/azureuser/cloudfiles/data/datastore/generalpurposeaccount/titanic_test.parquet')\r\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_titanic_raw.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500  None        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250  None        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500  None        S  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>None</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>None</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>None</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_titanic_raw.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "(891, 12)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def featurize_data(preped_data):\r\n",
        "    preped_data = preped_data.copy()\r\n",
        "    \r\n",
        "    gender_labels = {'male':0,'female':1}\r\n",
        "    preped_data['Sex'] = preped_data['Sex'].replace({'male':0,'female':1})\r\n",
        "\r\n",
        "    preped_data = preped_data.drop(['Name','Ticket','Cabin','Embarked'],axis =1)\r\n",
        "    preped_data['Age'] = preped_data['Age'].fillna(preped_data['Age'].mean())\r\n",
        "\r\n",
        "    X = preped_data.drop(['Survived'],axis =1)   #dropped unnecessary columns\r\n",
        "    y_train = preped_data['Survived']\r\n",
        "    num_columns = list(X.columns)\r\n",
        "\r\n",
        "    ct = make_column_transformer(\r\n",
        "        (MinMaxScaler(), num_columns),\r\n",
        "        (StandardScaler(), num_columns),\r\n",
        "        remainder='passthrough'\r\n",
        "    )\r\n",
        "\r\n",
        "    X_features = ct.fit_transform(X)\r\n",
        "    return preped_data, X_features, y_train"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preped_data, X_features, y_train = featurize_data(pdf_titanic_raw)\r\n"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "import mlflow\r\n",
        "\r\n",
        "mlflow.sklearn.autolog()\r\n",
        "\r\n",
        "experiment_name = \"Titanic_Experiment\"\r\n",
        "experiment_id = mlflow.create_experiment(experiment_name)\r\n",
        "\r\n",
        "with mlflow.start_run(experiment_id=experiment_id) as run:\r\n",
        "    log_reg = LogisticRegression(solver='liblinear', max_iter=100, penalty='l2', tol= 0.0001)\r\n",
        "    fitted_model = log_reg.fit(X_features, y_train)\r\n",
        "\r\n",
        "    isdir = os.path.isdir(\"outputs\")\r\n",
        "    if isdir:\r\n",
        "        shutil.rmtree(\"outputs\")\r\n",
        "    mlflow.sklearn.save_model(fitted_model, \"outputs\")"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preped_data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare\n0            1         0       3    0  22.0      1      0   7.2500\n1            2         1       1    1  38.0      1      0  71.2833\n2            3         1       3    1  26.0      0      0   7.9250\n3            4         1       1    1  35.0      1      0  53.1000\n4            5         0       3    0  35.0      0      0   8.0500",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore = ws.datastores['generalpurposeaccount']\r\n",
        "\r\n",
        "ds_X_train = Dataset.Tabular.register_pandas_dataframe(dataframe=preped_data, target=(datastore, 'titanic'), name=\"titanic_preped_data\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to titanic/611cec62-757f-4550-bc72-c52fd800c130/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_titanic_raw = Dataset.Tabular.register_pandas_dataframe(dataframe=pdf_titanic_raw, target=(datastore, 'titanic'), name=\"titanic_raw\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to titanic/8f4ab2a9-4f06-4052-8ea4-c36e150f0419/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model.register(model_path='outputs',\r\n",
        "                        model_name='titanic_model',\r\n",
        "                        datasets=[('raw_data', ds_titanic_raw), ('preped_data', ds_X_train)],\r\n",
        "                        description=\"Titanic survival classification model\",\r\n",
        "                        resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5),\r\n",
        "                        workspace=ws)\r\n",
        "                        "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Registering model titanic_model\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyper Parameter Tunning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm, datasets\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "parameters = {'solver':('liblinear', 'rbf'), \r\n",
        "              'penalty':('l1', 'l2'), \r\n",
        "              'tol' :[0.0001, 0.0002], \r\n",
        "              'max_iter': [50, 100]}\r\n",
        "              \r\n",
        "log_reg = LogisticRegression\r\n",
        "\r\n",
        "with mlflow.start_run(experiment_id=experiment_id) as run:\r\n",
        "    clf = GridSearchCV(log_reg, parameters)\r\n",
        "    clf.fit(X_features, y_train)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "30*20"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "600"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}